# 全方位カメラでのドローン検出用YOLOモデル

本プロジェクトは、全方位カメラを使用してドローンを検出するYOLOモデルを作成することを目的としています。以下は、この目標を達成するためのワークフローの概要です。

## 研究フロー

### 1. データセット作成
- **ビデオ撮影**: 衝突するケースと衝突しないケースを各方向で網羅した動画を撮影（図を含む）。
- **画像抽出**: 各動画から100枚の画像を抽出。
- **アノテーション**: [LabelBox](https://www.labelbox.com)を使用して画像にアノテーション。
- **形式変換**: JSONアノテーションファイルをYOLO形式のTXTファイルに変換。
- **データ分割**: 画像とアノテーションセットをランダムに80％をトレーニング用、20％をテスト用に分割し、それぞれ`train`および`vali`フォルダに配置。

### 2. モデル作成
- **YOLOv5トレーニング**: 準備したデータセットを使用してYOLOv5フレームワークでモデルを作成（実行コマンドを添付）。
- **モデル評価**: 作成したモデルを評価し、評価メトリクスを示す画像を添付。

### 3. 物体検出
- **出力カスタマイズ**:
  - 検出位置の軌跡を可視化するように出力を変更。
  - 検出位置をCSVファイルにエクスポート。
- **テスト**: テストデータを使用して検出。

### 4. 検出結果を使った考察
- **CSV分析**: CSVファイルをExcelに読み込み、さらなる分析を実施。
- **特徴分析**: 微分値（フレームごとの差）を使用して特徴を分析。
- **移動平均**: 移動平均を計算し、グラフにプロット。

---

このREADME.mdはVSCodeに直接コピペして使用できます。

